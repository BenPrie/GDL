{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scripts.dataset import *\n",
    "from scripts.model import S2CNN, IcoCNN\n",
    "from scripts.training import experiment, evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb1c22de8b9fd14c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e437ae66f9e67a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e784f07f361ed8aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d2bfbaba888383e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Storing models in a dictionary with keys \"Domain (training augmentation)\".\n",
    "# Initialise if/when used -- better for the memory.\n",
    "models = {\n",
    "    'Spherical (none)': None,\n",
    "    'Spherical (s2)'  : None,\n",
    "    'Spherical (ico)' : None,\n",
    "    \n",
    "    'Icosahedral (none)': None,\n",
    "    'Icosahedral (ico)' : None,\n",
    "    'Icosahedral (s2)'  : None\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5807637148c738e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# These are the architectures matching the data generated.\n",
    "def new_spherical_model():\n",
    "    return S2CNN(f_in=1, b_in=48, f_out=10)\n",
    "\n",
    "def new_icosahedral_model():\n",
    "    return IcoCNN(r=3, in_channels=1, out_channels=10, R_in=1, bias=True, smooth_vertices=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "950b67aa971df75c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Indices for train-val split.\n",
    "n_train = 50000\n",
    "train_idxs = np.arange(0, n_train)\n",
    "val_idxs = np.arange(n_train, 60000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3a2c76674e098"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76a58c4d7bfae1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spherical CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d928542b0fbe3954"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Spherical training data.\n",
    "with gzip.open('./data/spherical_none_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    spherical_none_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            dataset['images'][:, None, :, :].astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "with gzip.open('./data/spherical_ico_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    spherical_ico_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            dataset['images'][:, None, :, :].astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "with gzip.open('./data/spherical_s2_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    spherical_s2_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            dataset['images'][:, None, :, :].astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "    \n",
    "# Train-val split.\n",
    "spherical_none_val = Subset(spherical_none_train, val_idxs)\n",
    "spherical_none_train = Subset(spherical_none_train, train_idxs)\n",
    "spherical_ico_val = Subset(spherical_ico_train, val_idxs)\n",
    "spherical_ico_train = Subset(spherical_ico_train, train_idxs)\n",
    "spherical_s2_val = Subset(spherical_s2_train, val_idxs)\n",
    "spherical_s2_train = Subset(spherical_s2_train, train_idxs)\n",
    "\n",
    "# Dataloaders.\n",
    "batch_size = 64\n",
    "spherical_none_train_loader = DataLoader(spherical_none_train, batch_size, shuffle=True)\n",
    "spherical_ico_train_loader = DataLoader(spherical_ico_train, batch_size, shuffle=True)\n",
    "spherical_s2_train_loader = DataLoader(spherical_s2_train, batch_size, shuffle=True)\n",
    "spherical_none_val_loader = DataLoader(spherical_none_val, batch_size, shuffle=False)\n",
    "spherical_ico_val_loader = DataLoader(spherical_ico_val, batch_size, shuffle=False)\n",
    "spherical_s2_val_loader = DataLoader(spherical_s2_val, batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594ffda6954fdbdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### No augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abcf4b1ff867a0a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Spherical (none)'] = new_spherical_model()\n",
    "models['Spherical (none)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "decdc86581c47184"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Spherical (none)'],\n",
    "    spherical_none_train_loader,\n",
    "    spherical_none_val_loader,\n",
    "    device,\n",
    "    lr=5e-3,\n",
    "    n_epochs=20,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be9173587a37fc35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Spherical (none)'].state_dict(), './models/spherical_none.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28c0f166d7d599b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ico augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dc339f4e3a06a8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Spherical (ico)'] = new_spherical_model()\n",
    "models['Spherical (ico)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffaaeaa7969bffc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Spherical (ico)'],\n",
    "    spherical_ico_train_loader,\n",
    "    spherical_ico_val_loader,\n",
    "    device,\n",
    "    lr=5e-3,\n",
    "    n_epochs=20,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647978203cc3ac16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Spherical (ico)'].state_dict(), './models/spherical_ico.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6590368176abb3cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $S^2$ augmentation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b2d3fdfc1e13e65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Spherical (s2)'] = new_spherical_model()\n",
    "models['Spherical (s2)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d15b726e41a67211"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Spherical (s2)'],\n",
    "    spherical_s2_train_loader,\n",
    "    spherical_s2_val_loader,\n",
    "    device,\n",
    "    lr=5e-3,\n",
    "    n_epochs=20,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d39dd0a6ad9787bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Spherical (s2)'].state_dict(), './models/spherical_s2.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ecb72b64ebf28c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Icosahedral CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69da58bec19d27ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Icosahedral training data.\n",
    "with gzip.open('./data/icosahedral_none_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    icosahedral_none_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            np.array(dataset['images']).astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "with gzip.open('./data/icosahedral_ico_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    icosahedral_ico_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            np.array(dataset['images']).astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "with gzip.open('./data/icosahedral_s2_train.gz', 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    icosahedral_s2_train = TensorDataset(\n",
    "        torch.from_numpy(\n",
    "            np.array(dataset['images']).astype(np.float32)\n",
    "        ),\n",
    "        torch.from_numpy(dataset['labels'].astype(np.int64))\n",
    "    )\n",
    "    \n",
    "# Train-val split.\n",
    "icosahedral_none_val = Subset(icosahedral_none_train, val_idxs)\n",
    "icosahedral_none_train = Subset(icosahedral_none_train, train_idxs)\n",
    "icosahedral_ico_val = Subset(icosahedral_ico_train, val_idxs)\n",
    "icosahedral_ico_train = Subset(icosahedral_ico_train, train_idxs)\n",
    "icosahedral_s2_val = Subset(icosahedral_s2_train, val_idxs)\n",
    "icosahedral_s2_train = Subset(icosahedral_s2_train, train_idxs)\n",
    "\n",
    "# Dataloaders.\n",
    "batch_size = 64\n",
    "icosahedral_none_train_loader = DataLoader(icosahedral_none_train, batch_size, shuffle=True)\n",
    "icosahedral_ico_train_loader = DataLoader(icosahedral_ico_train, batch_size, shuffle=True)\n",
    "icosahedral_s2_train_loader = DataLoader(icosahedral_s2_train, batch_size, shuffle=True)\n",
    "icosahedral_none_val_loader = DataLoader(icosahedral_none_val, batch_size, shuffle=False)\n",
    "icosahedral_ico_val_loader = DataLoader(icosahedral_ico_val, batch_size, shuffle=False)\n",
    "icosahedral_s2_val_loader = DataLoader(icosahedral_s2_val, batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab00b477df3e0e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### No augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd39a6df20a5566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Icosahedral (none)'] = new_icosahedral_model()\n",
    "models['Icosahedral (none)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "628467146ab2a61a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Icosahedral (none)'],\n",
    "    icosahedral_none_train_loader,\n",
    "    icosahedral_none_val_loader,\n",
    "    device,\n",
    "    lr=1e-4,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d17bf037407b12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Icosahedral (none)'].state_dict(), './models/icosahedral_none.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2243364d2bd77402"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ico augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af3384c1fd7c13e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Icosahedral (ico)'] = new_icosahedral_model()\n",
    "models['Icosahedral (ico)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ccd450e8da3cce5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Icosahedral (ico)'],\n",
    "    icosahedral_ico_train_loader,\n",
    "    icosahedral_ico_val_loader,\n",
    "    device,\n",
    "    lr=1e-4,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7515f0838b8ef9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Icosahedral (ico)'].state_dict(), './models/icosahedral_ico.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76d518d5669fd69b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $S^2$ augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95dcc0dd2f45c705"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model.\n",
    "models['Icosahedral (s2)'] = new_icosahedral_model()\n",
    "models['Icosahedral (s2)'].to(device)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa15ef593bbb7aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment(\n",
    "    models['Icosahedral (s2)'],\n",
    "    icosahedral_s2_train_loader,\n",
    "    icosahedral_s2_val_loader,\n",
    "    device,\n",
    "    lr=1e-3,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c836da49d9299fb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(models['Icosahedral (s2)'].state_dict(), './models/icosahedral_s2.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c2eb1e926366e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models['Icosahedral (s2)'].load_state_dict(torch.load('./models/icosahedral_s2.pth'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4886151b6bf9ea6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for x, y in tqdm(icosahedral_s2_val_loader):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    out = models['Icosahedral (ico)'](x)\n",
    "    correct += (out.argmax(dim=1) == y).sum().item()\n",
    "print(correct / len(icosahedral_s2_val_loader.dataset))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f5ac2c5c55ac14"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Online Augmentation Training\n",
    "\n",
    "Having fixed rotated samples in the training set doesn't always seem to work. And using all 60 symmetries in one go is just simply not feasible. So, as a middle ground, we'll randomly rotate the sample at train (or test) time to increase the probability that we see more symmetries as training goes on."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "819bfa3e099faf04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "These work with different data. Instead of the projections onto the sphere, this works with the raw signals so that we may rotate then project ourselves during inference."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdffe48462d96f39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "880f7f5ed8ba43c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='./data', train=True, download=True)\n",
    "train_data = train_dataset.train_data.numpy().reshape(-1, 28, 28).astype(np.float64)\n",
    "train_labels = train_dataset.train_labels.numpy()\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(\n",
    "    torch.from_numpy(train_data[train_idxs]),\n",
    "    torch.from_numpy(train_labels[train_idxs])\n",
    "), batch_size=64)\n",
    "val_loader = DataLoader(TensorDataset(\n",
    "    torch.from_numpy(train_data[val_idxs]),\n",
    "    torch.from_numpy(train_labels[val_idxs])\n",
    "), batch_size=64)\n",
    "\n",
    "model = new_spherical_model()\n",
    "model.to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "grid = get_projection_grid(b=24)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f24fe80d6072cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def augment_and_project(x, grid, augment):\n",
    "    # Augmentation.\n",
    "    if augment == 's2':\n",
    "        # Random continuous rotation.\n",
    "        rotation_matrix = random_rotation_matrix()\n",
    "        rotated_grid = rotate_grid(rotation_matrix, grid)\n",
    "    elif augment == 'ico':\n",
    "        # Random discrete rotation from the icosahedral symmetry group.\n",
    "        icosahedral_group = R.create_group('I')\n",
    "        icosahedral_rotations = icosahedral_group.as_matrix()\n",
    "        rotation_matrix = random.choice(icosahedral_rotations)\n",
    "        rotated_grid = rotate_grid(rotation_matrix, grid)\n",
    "    else:\n",
    "        rotated_grid = grid\n",
    "        \n",
    "    # Project.\n",
    "    x = project_2d_on_sphere(x.numpy(), rotated_grid)\n",
    "    return torch.from_numpy(\n",
    "        x[:, None, :, :].astype(np.float32)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94ac0581b1e80042"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_one_epoch(model, grid, train_loader, optimizer, criterion, device, augment='none', ico_grid=None, verbose=False):\n",
    "    model.train()\n",
    "    running_loss = .0\n",
    "    \n",
    "    for x, y in (tqdm(train_loader, desc='Train.') if verbose else train_loader):\n",
    "        # Reset gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Augment and project.\n",
    "        x = augment_and_project(x, grid, augment)\n",
    "        #print('after augment:', x.shape)\n",
    "        \n",
    "        # Onto the icosahedron.\n",
    "        if ico_grid is not None:\n",
    "            ico_x = []\n",
    "            for signal in x:\n",
    "                ico_x.append(s2_to_ico(signal, ico_grid))\n",
    "            x = torch.tensor(np.array(ico_x))\n",
    "            \n",
    "        #print('after ico:', x.shape)\n",
    "        \n",
    "        # Move to device.\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Model and loss.\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        \n",
    "        # Backprop.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update loss.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Return average loss over the epoch.\n",
    "    return running_loss / len(train_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26a203840778f073"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(model, grid, test_loader, criterion, device, augment='none', ico_grid=None, verbose=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in (tqdm(test_loader, desc='Eval.') if verbose else test_loader):\n",
    "            \n",
    "            # Augment and project.\n",
    "            x = augment_and_project(x, grid, augment)\n",
    "            \n",
    "            # Onto the icosahedron.\n",
    "            if ico_grid is not None:\n",
    "                ico_x = []\n",
    "                for signal in x:\n",
    "                    ico_x.append(s2_to_ico(signal, ico_grid))\n",
    "                x = torch.tensor(np.array(ico_x))\n",
    "            \n",
    "            # Move to device.\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Model and loss.\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            # Update loss.\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Argmax to get predicted label.\n",
    "            pred = out.argmax(dim=1)\n",
    "\n",
    "            # Update accuracy.\n",
    "            correct += (pred == y).sum().item()\n",
    "            \n",
    "    # Return average loss and accuracy over the epoch.\n",
    "    return running_loss / len(test_loader), correct / len(test_loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa08f337350da930"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Track the losses and val accuracies.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "n_epochs = 10\n",
    "augment = 'ico'\n",
    "for epoch in tqdm(range(1, n_epochs + 1), desc='Experiment.'):\n",
    "    # Train.\n",
    "    train_loss = train_one_epoch(model, grid, train_loader, optimiser, criterion, device, augment, verbose=True)\n",
    "\n",
    "    # Evaluate.\n",
    "    val_loss, val_acc = evaluate_one_epoch(model, grid, val_loader, criterion, device, augment, verbose=True)\n",
    "\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Appends.\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f94ff7088f1126dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/spherical_ico.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e4b4bc23a09df8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ico_model = new_icosahedral_model()\n",
    "ico_model.to(device)\n",
    "optimiser = torch.optim.Adam(ico_model.parameters(), lr=5e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "grid = get_projection_grid(b=24)\n",
    "ico_grid = icosahedral_grid_coordinates(r=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40dd84259b3bc8ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Track the losses and val accuracies.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "n_epochs = 20\n",
    "augment = 'none'\n",
    "for epoch in tqdm(range(1, n_epochs + 1), desc='Experiment.'):\n",
    "    # Train.\n",
    "    train_loss = train_one_epoch(ico_model, grid, train_loader, optimiser, criterion, device, augment, ico_grid, verbose=True)\n",
    "\n",
    "    # Evaluate.\n",
    "    val_loss, val_acc = evaluate_one_epoch(ico_model, grid, val_loader, criterion, device, augment, ico_grid, verbose=True)\n",
    "\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Appends.\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd898a440a6ffa4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(ico_model.state_dict(), './models/online_augment/icosahedral_none.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be29aea611e4f402"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ico_model = new_icosahedral_model()\n",
    "ico_model.to(device)\n",
    "optimiser = torch.optim.Adam(ico_model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "grid = get_projection_grid(b=24)\n",
    "ico_grid = icosahedral_grid_coordinates(r=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a825d51ee3e397d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Track the losses and val accuracies.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "n_epochs = 20\n",
    "augment = 'ico'\n",
    "for epoch in tqdm(range(1, n_epochs + 1), desc='Experiment.'):\n",
    "    # Train.\n",
    "    train_loss = train_one_epoch(ico_model, grid, train_loader, optimiser, criterion, device, augment, ico_grid, verbose=False)\n",
    "\n",
    "    # Evaluate.\n",
    "    val_loss, val_acc = evaluate_one_epoch(ico_model, grid, val_loader, criterion, device, augment, ico_grid, verbose=False)\n",
    "\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Appends.\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57baf2dfd93e4544"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(ico_model.state_dict(), './models/online_augment/icosahedral_ico.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f506215002ff781"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ico_model = new_icosahedral_model()\n",
    "ico_model.to(device)\n",
    "optimiser = torch.optim.Adam(ico_model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "grid = get_projection_grid(b=24)\n",
    "ico_grid = icosahedral_grid_coordinates(r=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165f70ae3ee1b03b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Track the losses and val accuracies.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "n_epochs = 20\n",
    "augment = 's2'\n",
    "for epoch in tqdm(range(1, n_epochs + 1), desc='Experiment.'):\n",
    "    # Train.\n",
    "    train_loss = train_one_epoch(ico_model, grid, train_loader, optimiser, criterion, device, augment, ico_grid, verbose=False)\n",
    "\n",
    "    # Evaluate.\n",
    "    val_loss, val_acc = evaluate_one_epoch(ico_model, grid, val_loader, criterion, device, augment, ico_grid, verbose=False)\n",
    "\n",
    "    print(f'Epoch {epoch}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Appends.\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a51b984cc4bb63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(ico_model.state_dict(), './models/online_augment/icosahedral_s2.pth')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e05ffe2275b371"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e5bd4642a897a4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='./data', train=False, download=True)\n",
    "test_data = test_dataset.test_data.numpy().reshape(-1, 28, 28).astype(np.float64)\n",
    "test_labels = test_dataset.test_labels.numpy()\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(\n",
    "    torch.from_numpy(test_data),\n",
    "    torch.from_numpy(test_labels)\n",
    "), batch_size=64)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab5101dfc5816f5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid = get_projection_grid(b=24)\n",
    "ico_grid = icosahedral_grid_coordinates(r=3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1cef050298adcc1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ico_models = {\n",
    "    # Indexed by the dataset on which it was trained.\n",
    "    'none': new_icosahedral_model(),\n",
    "    'ico' : new_icosahedral_model(),\n",
    "    's2'  : new_icosahedral_model()\n",
    "}\n",
    "\n",
    "for augment, model in ico_models.items():\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(f'./models/online_augment/icosahedral_{augment}.pth'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c29853877e988e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'none': {},\n",
    "    'ico' : {},\n",
    "    's2'  : {}\n",
    "}\n",
    "\n",
    "for test_augment, stat_dict in stats.items():\n",
    "    for train_augment, model in ico_models.items():\n",
    "        stat_dict[train_augment] = evaluate_one_epoch(\n",
    "            model=model,\n",
    "            grid=grid,\n",
    "            test_loader=test_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            augment=test_augment,\n",
    "            ico_grid=ico_grid,\n",
    "            verbose=True\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "325657f5f2b4668e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea2353e789b7ef7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def do_plot(save_path):\n",
    "    # --- Data Preparation ---\n",
    "    test_datasets = list(stats.keys()) # Categories for the x-axis ('none', 'ico', 's2')\n",
    "    # Assuming train datasets are the same for all test datasets\n",
    "    train_datasets = list(stats[test_datasets[0]].keys()) # Groups within each x-category\n",
    "    \n",
    "    # Extract the scores (first value of the tuple)\n",
    "    # We want a structure where we have scores grouped by the training dataset\n",
    "    scores_by_train = {train_ds: [] for train_ds in train_datasets}\n",
    "    for test_ds in test_datasets:\n",
    "        for train_ds in train_datasets:\n",
    "            # Append the score for the current train_ds when tested on test_ds\n",
    "            # Using [0] to get the first value (accuracy) from the tuple\n",
    "            score = stats[test_ds][train_ds][1]\n",
    "            scores_by_train[train_ds].append(score)\n",
    "    \n",
    "    # --- Plotting Setup ---\n",
    "    n_test_datasets = len(test_datasets)\n",
    "    n_train_datasets = len(train_datasets)\n",
    "    \n",
    "    # Calculate bar positions\n",
    "    x_indices = np.arange(n_test_datasets) # Base positions for the groups [0, 1, 2]\n",
    "    bar_width = 0.25 # Adjust as needed for spacing\n",
    "    group_width = bar_width * n_train_datasets\n",
    "    offset_for_centering = (group_width - bar_width) / 2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 5)) # Adjust figure size if needed\n",
    "    \n",
    "    cmap_name = 'Set3'\n",
    "    colormap = cm.get_cmap(cmap_name)\n",
    "    colors = [colormap(i) for i in np.linspace(0, 0.85, n_train_datasets)]\n",
    "    ax.set_prop_cycle(color=colors)\n",
    "    \n",
    "    # --- Create Bars ---\n",
    "    for i, train_ds in enumerate(train_datasets):\n",
    "        # Calculate the position for each bar in this group\n",
    "        bar_positions = x_indices - offset_for_centering + i * bar_width\n",
    "        # Get the scores for this training dataset across all test datasets\n",
    "        scores = scores_by_train[train_ds]\n",
    "        train_ds = train_ds.capitalize()\n",
    "        # Plot the bars\n",
    "        rects = ax.bar(bar_positions, scores, bar_width, label=f'{train_ds}')\n",
    "        # Optional: Add labels on top of bars\n",
    "        ax.bar_label(rects, padding=-18, fmt=f'%.2f\\n\\n{train_ds}') # Adjust formatting as needed\n",
    "    \n",
    "    # --- Customize Plot ---\n",
    "    ax.set_xlabel('Test-time Augmentation', fontsize=14)\n",
    "    ax.set_ylabel('Test Accuracy', fontsize=14)\n",
    "    #ax.set_title('Model Performance by Training and Testing Dataset')\n",
    "    ax.set_xticks(x_indices) # Set the positions of the x-axis ticks\n",
    "    ax.set_xticklabels([x.capitalize() for x in test_datasets]) # Set the labels for the x-axis ticks\n",
    "    ax.legend(title='Train-time\\nAugmentation ', loc=(.088, .05)) # Add a legend to identify bar colors\n",
    "    \n",
    "    ax.spines['top'].set_visible(False) # Optional: Remove top border\n",
    "    ax.spines['right'].set_visible(False) # Optional: Remove right border\n",
    "    plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    \n",
    "    # --- Show Plot ---\n",
    "    plt.show()\n",
    "    \n",
    "do_plot('./figures/performance_by_augment.pdf')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2caebb13e5b2f905"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
